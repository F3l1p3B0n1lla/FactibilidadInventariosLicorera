{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NPI5PsgffJg"
   },
   "source": [
    "## Proyecto Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3QRoWE9ffJh"
   },
   "source": [
    "pip install pandas as pd\n",
    "pip install numpy as np\n",
    "pip install pandas pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mta7xA71TpuK"
   },
   "outputs": [],
   "source": [
    "# Carga de librerias\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar la conexion a SQL SERVER\n",
    "\n",
    "#import pyodbc\n",
    "\n",
    "#server = \"LAPTOP-ET6CVE9Q\\SQLEXPRESS\"  # Ejemplo: \"localhost\\SQLEXPRESS\"\n",
    "#database = \"Licorera\"\n",
    "#username = \"LAPTOP-ET6CVE9Q\\Cami\"\n",
    "#password = \"CONTRASE√ëA\"\n",
    "#driver = \"{SQL Server}\"\n",
    "\n",
    "# üîÑ Crear conexi√≥n\n",
    "#conn = pyodbc.connect(\n",
    "#    f\"DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password}\"\n",
    ")\n",
    "#cursor = conn.cursor()\n",
    "#print(\"‚úÖ Conexi√≥n exitosa a SQL Server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Cami\\AppData\\Local\\Temp\\ipykernel_14960\\239218762.py:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  ruta_carpeta = \"C:\\Proyecto Final Henry\\DataBase\"\n"
     ]
    }
   ],
   "source": [
    "# Importar multiples archivos CSV\n",
    "# üìÇ Carpeta donde est√°n los archivos CSV\n",
    "ruta_carpeta = \"C:\\Proyecto Final Henry\\DataBase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Cami\\AppData\\Local\\Temp\\ipykernel_14960\\1039401825.py:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  for archivo in os.listdir(\"C:\\Proyecto Final Henry\\DataBase\"):\n",
      "C:\\Users\\Cami\\AppData\\Local\\Temp\\ipykernel_14960\\1039401825.py:4: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  ruta_completa = os.path.join(\"C:\\Proyecto Final Henry\\DataBase\", archivo)\n",
      "C:\\Users\\Cami\\AppData\\Local\\Temp\\ipykernel_14960\\1039401825.py:2: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  for archivo in os.listdir(\"C:\\Proyecto Final Henry\\DataBase\"):\n",
      "C:\\Users\\Cami\\AppData\\Local\\Temp\\ipykernel_14960\\1039401825.py:4: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  ruta_completa = os.path.join(\"C:\\Proyecto Final Henry\\DataBase\", archivo)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# üîÑ Recorremos todos los archivos en la carpeta\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m archivo \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProyecto Final Henry\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataBase\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m archivo\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m archivo\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# Verifica si es CSV o Excel\u001b[39;00m\n\u001b[0;32m      4\u001b[0m         ruta_completa \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProyecto Final Henry\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataBase\u001b[39m\u001b[38;5;124m\"\u001b[39m, archivo)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# üîÑ Recorremos todos los archivos en la carpeta\n",
    "#for archivo in os.listdir(\"C:\\Proyecto Final Henry\\DataBase\"):\n",
    "#    if archivo.endswith(\".csv\") or archivo.endswith(\".xlsx\"):  # Verifica si es CSV o Excel\n",
    "#        ruta_completa = os.path.join(\"C:\\Proyecto Final Henry\\DataBase\", archivo)\n",
    "#        \n",
    "        # üì• Cargar archivo CSV o Excel con Pandas\n",
    "#        if archivo.endswith(\".csv\"):\n",
    "#            df = pd.read_csv(ruta_completa)\n",
    "#        else:\n",
    "#            df = pd.read_excel(ruta_completa)\n",
    "#\n",
    "#        # üìå Crear la tabla en SQL Server (opcional, si no existe)\n",
    "#        nombre_tabla = archivo.split(\".\")[0]  # Eliminar la extensi√≥n del archivo\n",
    "#        columnas = \", \".join([f\"[{col}]\" for col in df.columns])  # Formatear columnas\n",
    "        \n",
    "#        sql_create = f\"CREATE TABLE {nombre_tabla} ({columnas} NVARCHAR(MAX))\"\n",
    "#        try:\n",
    "#            cursor.execute(sql_create)\n",
    "#            conn.commit()\n",
    "#            print(f\"üõ† Tabla {nombre_tabla} creada en SQL Server.\")\n",
    "#        except:\n",
    "#            print(f\"‚ö†Ô∏è La tabla {nombre_tabla} ya existe, insertando datos...\")\n",
    "\n",
    "        # üîÑ Insertar datos en la tabla\n",
    "#        for _, row in df.iterrows():\n",
    "#            valores = \"', '\".join(map(str, row))\n",
    "#            sql_insert = f\"INSERT INTO {nombre_tabla} ({columnas}) VALUES ('{valores}')\"\n",
    "#            cursor.execute(sql_insert)\n",
    "\n",
    "#        conn.commit()\n",
    "#        print(f\"‚úÖ Datos de {archivo} insertados en {nombre_tabla}\")\n",
    "\n",
    "# Cerrar conexi√≥n\n",
    "#cursor.close()\n",
    "#conn.close()\n",
    "#print(\"üöÄ Importaci√≥n finalizada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicio de revisi√≥n, filtrado de datos y limpieza de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Brand                  Description  Price   Size Volume  Classification  \\\n",
      "0     58  Gekkeikan Black & Gold Sake  12.99  750mL    750               1   \n",
      "1     62     Herradura Silver Tequila  36.99  750mL    750               1   \n",
      "2     63   Herradura Reposado Tequila  38.99  750mL    750               1   \n",
      "3     72         No. 3 London Dry Gin  34.99  750mL    750               1   \n",
      "4     75    Three Olives Tomato Vodka  14.99  750mL    750               1   \n",
      "\n",
      "   PurchasePrice  VendorNumber                   VendorName  \n",
      "0           9.28          8320  SHAW ROSS INT L IMP LTD      \n",
      "1          28.67          1128  BROWN-FORMAN CORP            \n",
      "2          30.46          1128  BROWN-FORMAN CORP            \n",
      "3          26.11          9165  ULTRA BEVERAGE COMPANY LLP   \n",
      "4          10.94          7245  PROXIMO SPIRITS INC.         \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ruta del archivo CSV (ajusta seg√∫n la ubicaci√≥n de tu archivo)\n",
    "ruta_csv1 = r\"C:\\\\Proyecto Final Henry\\\\DataBase\\\\2017PurchasePricesDec.csv\"\n",
    "\n",
    "# Cargar el CSV en un DataFrame de Pandas\n",
    "df1 = pd.read_csv(ruta_csv1)\n",
    "\n",
    "# Mostrar las primeras filas del CSV\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12261, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12261, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brand             0\n",
       "Description       1\n",
       "Price             0\n",
       "Size              1\n",
       "Volume            1\n",
       "Classification    0\n",
       "PurchasePrice     0\n",
       "VendorNumber      0\n",
       "VendorName        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se revisa la cantidad de datos faltantes en la base de datos para continuar\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las filas de datos faltantes (si son pocos datos)\n",
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Size</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Classification</th>\n",
       "      <th>PurchasePrice</th>\n",
       "      <th>VendorNumber</th>\n",
       "      <th>VendorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand, Description, Price, Size, Volume, Classification, PurchasePrice, VendorNumber, VendorName]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar todas las filas con valores faltantes: \n",
    "df1[df1.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar cuantas filas tienen datos faltante:\n",
    "df1.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12260, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Ver valores duplicados df1 es tu DataFrame\n",
    "duplicados = df1.duplicated().sum()\n",
    "\n",
    "print(f\"Total de filas duplicadas: {duplicados}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el dataset revisado, a el cual se le elimino una fila convalores NaN y se guarda a un nuevo archivo csv para poderlo utilizar posteriormente.\n",
    "df1.to_csv(\"2017PurchasePricesDecRev.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         InventoryId  Store          City  Brand                  Description  \\\n",
      "0  1_HARDERSFIELD_58      1  HARDERSFIELD     58  Gekkeikan Black & Gold Sake   \n",
      "1  1_HARDERSFIELD_60      1  HARDERSFIELD     60       Canadian Club 1858 VAP   \n",
      "2  1_HARDERSFIELD_62      1  HARDERSFIELD     62     Herradura Silver Tequila   \n",
      "3  1_HARDERSFIELD_63      1  HARDERSFIELD     63   Herradura Reposado Tequila   \n",
      "4  1_HARDERSFIELD_72      1  HARDERSFIELD     72         No. 3 London Dry Gin   \n",
      "\n",
      "    Size  onHand  Price   startDate  \n",
      "0  750mL       8  12.99  2016-01-01  \n",
      "1  750mL       7  10.99  2016-01-01  \n",
      "2  750mL       6  36.99  2016-01-01  \n",
      "3  750mL       3  38.99  2016-01-01  \n",
      "4  750mL       6  34.99  2016-01-01  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ruta del archivo CSV (ajusta seg√∫n la ubicaci√≥n de tu archivo)\n",
    "ruta_csv2 = r\"C:\\\\Proyecto Final Henry\\\\DataBase\\\\BegInvFINAL12312016.csv\"\n",
    "\n",
    "# Cargar el CSV en un DataFrame de Pandas\n",
    "df2 = pd.read_csv(ruta_csv2)\n",
    "\n",
    "# Mostrar las primeras filas del CSV\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206529, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InventoryId    0\n",
       "Store          0\n",
       "City           0\n",
       "Brand          0\n",
       "Description    0\n",
       "Size           0\n",
       "onHand         0\n",
       "Price          0\n",
       "startDate      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se revisa la cantidad de datos faltantes en la base de datos para continuar\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar cuantas filas tienen datos faltante:\n",
    "df2.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Ver valores duplicados df2 es tu DataFrame\n",
    "duplicados = df2.duplicated().sum()\n",
    "\n",
    "print(f\"Total de filas duplicadas: {duplicados}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         InventoryId  Store          City  Brand                  Description  \\\n",
      "0  1_HARDERSFIELD_58      1  HARDERSFIELD     58  Gekkeikan Black & Gold Sake   \n",
      "1  1_HARDERSFIELD_62      1  HARDERSFIELD     62     Herradura Silver Tequila   \n",
      "2  1_HARDERSFIELD_63      1  HARDERSFIELD     63   Herradura Reposado Tequila   \n",
      "3  1_HARDERSFIELD_72      1  HARDERSFIELD     72         No. 3 London Dry Gin   \n",
      "4  1_HARDERSFIELD_75      1  HARDERSFIELD     75    Three Olives Tomato Vodka   \n",
      "\n",
      "    Size  onHand  Price     endDate  \n",
      "0  750mL      11  12.99  2016-12-31  \n",
      "1  750mL       7  36.99  2016-12-31  \n",
      "2  750mL       7  38.99  2016-12-31  \n",
      "3  750mL       4  34.99  2016-12-31  \n",
      "4  750mL       7  14.99  2016-12-31  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ruta del archivo CSV (ajusta seg√∫n la ubicaci√≥n de tu archivo)\n",
    "ruta_csv3 = r\"C:\\\\Proyecto Final Henry\\\\DataBase\\\\EndInvFINAL12312016.csv\"\n",
    "\n",
    "# Cargar el CSV en un DataFrame de Pandas\n",
    "df3 = pd.read_csv(ruta_csv3)\n",
    "\n",
    "# Mostrar las primeras filas del CSV\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224489, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InventoryId       0\n",
       "Store             0\n",
       "City           1284\n",
       "Brand             0\n",
       "Description       0\n",
       "Size              0\n",
       "onHand            0\n",
       "Price             0\n",
       "endDate           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se revisa la cantidad de datos faltantes en la base de datos para continuar\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1284)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar cuantas filas tienen datos faltante:\n",
    "df3.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InventoryId</th>\n",
       "      <th>Store</th>\n",
       "      <th>City</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Size</th>\n",
       "      <th>onHand</th>\n",
       "      <th>Price</th>\n",
       "      <th>endDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113895</th>\n",
       "      <td>46__58</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>Gekkeikan Black &amp; Gold Sake</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113896</th>\n",
       "      <td>46__62</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>Herradura Silver Tequila</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>36.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113897</th>\n",
       "      <td>46__63</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>Herradura Reposado Tequila</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113898</th>\n",
       "      <td>46__77</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>Three Olives Espresso Vodka</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>14.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113899</th>\n",
       "      <td>46__106</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106</td>\n",
       "      <td>Mr Boston Peach Schnapps</td>\n",
       "      <td>Liter</td>\n",
       "      <td>0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115174</th>\n",
       "      <td>46__46447</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46447</td>\n",
       "      <td>Gascon Malbec Mendoza</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>10.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115175</th>\n",
       "      <td>46__46458</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46458</td>\n",
       "      <td>Layer Cake Barosa Shiraz</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>15.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115176</th>\n",
       "      <td>46__46476</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46476</td>\n",
       "      <td>Tilia Malbec Mendoza</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115177</th>\n",
       "      <td>46__46764</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46764</td>\n",
       "      <td>Clayhouse Adobe Red Paso Rbl</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115178</th>\n",
       "      <td>46__46830</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46830</td>\n",
       "      <td>Pacific Rim Sweet Rsl</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>8.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       InventoryId  Store City  Brand                   Description   Size  \\\n",
       "113895      46__58     46  NaN     58   Gekkeikan Black & Gold Sake  750mL   \n",
       "113896      46__62     46  NaN     62      Herradura Silver Tequila  750mL   \n",
       "113897      46__63     46  NaN     63    Herradura Reposado Tequila  750mL   \n",
       "113898      46__77     46  NaN     77   Three Olives Espresso Vodka  750mL   \n",
       "113899     46__106     46  NaN    106      Mr Boston Peach Schnapps  Liter   \n",
       "...            ...    ...  ...    ...                           ...    ...   \n",
       "115174   46__46447     46  NaN  46447         Gascon Malbec Mendoza  750mL   \n",
       "115175   46__46458     46  NaN  46458      Layer Cake Barosa Shiraz  750mL   \n",
       "115176   46__46476     46  NaN  46476          Tilia Malbec Mendoza  750mL   \n",
       "115177   46__46764     46  NaN  46764  Clayhouse Adobe Red Paso Rbl  750mL   \n",
       "115178   46__46830     46  NaN  46830         Pacific Rim Sweet Rsl  750mL   \n",
       "\n",
       "        onHand  Price     endDate  \n",
       "113895       0  12.99  2016-12-31  \n",
       "113896       0  36.99  2016-12-31  \n",
       "113897       0  38.99  2016-12-31  \n",
       "113898       0  14.99  2016-12-31  \n",
       "113899       0   4.49  2016-12-31  \n",
       "...        ...    ...         ...  \n",
       "115174       0  10.99  2016-12-31  \n",
       "115175       0  15.99  2016-12-31  \n",
       "115176       0   9.99  2016-12-31  \n",
       "115177       0  11.99  2016-12-31  \n",
       "115178       0   8.99  2016-12-31  \n",
       "\n",
       "[1284 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar todas las filas con valores faltantes: \n",
    "df3[df3.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Ver valores duplicados df3 es tu DataFrame\n",
    "duplicados = df3.duplicated().sum()\n",
    "\n",
    "print(f\"Total de filas duplicadas: {duplicados}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos en la columna 'City':\n",
      "['HARDERSFIELD' 'ASHBORNE' 'HORNSEY' 'EANVERNESS' 'SUTTON' 'GOULCREST'\n",
      " 'STANMORE' 'ALNERWICK' 'BLACKPOOL' 'CARDEND' 'LEESIDE' 'TARMSWORTH'\n",
      " 'BROMWICH' 'WANBORNE' 'LUNDY' 'OLDHAM' 'FURNESS' 'WINTERVALE'\n",
      " 'BREDWARDINE' 'BALERNO' 'SHARNWICK' 'ARBINGTON' 'PALPERROTH' 'CAERSHIRE'\n",
      " \"KNIFE'S EDGE\" 'MOUNTMEND' 'LARNWICK' 'AYLESBURY' 'CULCHETH' 'PITMERDEN'\n",
      " 'HALIVAARA' 'LEWES' 'PAETHSMOUTH' 'EASTHALLOW' 'BULLMAR' 'BLACK HOLLOW'\n",
      " 'WOLFORD' 'PORTHCRAWL' 'VERITAS' nan \"PELLA'S WISH\" 'NORFOLK' 'GARIGILL'\n",
      " 'ABERDEEN' 'GRAYCOTT' 'HILLFAR' 'GUTHRAM' 'DRY GULCH' \"BEGGAR'S HOLE\"\n",
      " 'LANTEGLOS' 'HARTLEPOOL' 'CLAETHORPES' 'IRRAGIN' 'AETHELNEY' 'KILMARNOCK'\n",
      " 'SWORDBREAK' 'CESTERFIELD' 'LUTON' 'SOLARIS' 'KELD' 'CLARCTON'\n",
      " 'DONCASTER' 'PAENTMARWY' 'BARNCOMBE' 'TAMWORTH' 'EASTHAVEN' 'BALLYMENA'\n",
      " 'PEMBROKE']\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que tu DataFrame es df4\n",
    "unique_values = df3['City'].unique()\n",
    "\n",
    "print(\"Valores √∫nicos en la columna 'City':\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la media, moda y mediana de City para el dataframe df3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorNumber                   VendorName InvoiceDate  PONumber  \\\n",
      "0           105  ALTAMAR BRANDS LLC           2016-01-04      8124   \n",
      "1          4466  AMERICAN VINTAGE BEVERAGE    2016-01-07      8137   \n",
      "2           388  ATLANTIC IMPORTING COMPANY   2016-01-09      8169   \n",
      "3           480  BACARDI USA INC              2016-01-12      8106   \n",
      "4           516  BANFI PRODUCTS CORP          2016-01-07      8170   \n",
      "\n",
      "       PODate     PayDate  Quantity    Dollars  Freight Approval  \n",
      "0  2015-12-21  2016-02-16         6     214.26     3.47      NaN  \n",
      "1  2015-12-22  2016-02-21        15     140.55     8.57      NaN  \n",
      "2  2015-12-24  2016-02-16         5     106.60     4.61      NaN  \n",
      "3  2015-12-20  2016-02-05     10100  137483.78  2935.20      NaN  \n",
      "4  2015-12-24  2016-02-12      1935   15527.25   429.20      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ruta del archivo CSV (ajusta seg√∫n la ubicaci√≥n de tu archivo)\n",
    "ruta_csv4 = r\"C:\\\\Proyecto Final Henry\\\\DataBase\\\\InvoicePurchases12312016.csv\"\n",
    "\n",
    "# Cargar el CSV en un DataFrame de Pandas\n",
    "df4 = pd.read_csv(ruta_csv4)\n",
    "\n",
    "# Mostrar las primeras filas del CSV\n",
    "print(df4.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5543, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar el total de filas y columnas\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorNumber       0\n",
       "VendorName         0\n",
       "InvoiceDate        0\n",
       "PONumber           0\n",
       "PODate             0\n",
       "PayDate            0\n",
       "Quantity           0\n",
       "Dollars            0\n",
       "Freight            0\n",
       "Approval        5169\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se revisa la cantidad de datos faltantes en la base de datos para continuar\n",
    "df4.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorNumber</th>\n",
       "      <th>VendorName</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>PONumber</th>\n",
       "      <th>PODate</th>\n",
       "      <th>PayDate</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Dollars</th>\n",
       "      <th>Freight</th>\n",
       "      <th>Approval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>ALTAMAR BRANDS LLC</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>8124</td>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>6</td>\n",
       "      <td>214.26</td>\n",
       "      <td>3.47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4466</td>\n",
       "      <td>AMERICAN VINTAGE BEVERAGE</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>8137</td>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>15</td>\n",
       "      <td>140.55</td>\n",
       "      <td>8.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>388</td>\n",
       "      <td>ATLANTIC IMPORTING COMPANY</td>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>8169</td>\n",
       "      <td>2015-12-24</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>5</td>\n",
       "      <td>106.60</td>\n",
       "      <td>4.61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>BACARDI USA INC</td>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>8106</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>10100</td>\n",
       "      <td>137483.78</td>\n",
       "      <td>2935.20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>516</td>\n",
       "      <td>BANFI PRODUCTS CORP</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>8170</td>\n",
       "      <td>2015-12-24</td>\n",
       "      <td>2016-02-12</td>\n",
       "      <td>1935</td>\n",
       "      <td>15527.25</td>\n",
       "      <td>429.20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>9622</td>\n",
       "      <td>WEIN BAUER INC</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>13626</td>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>90</td>\n",
       "      <td>1563.00</td>\n",
       "      <td>8.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>9625</td>\n",
       "      <td>WESTERN SPIRITS BEVERAGE CO</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>13661</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>2017-02-18</td>\n",
       "      <td>4617</td>\n",
       "      <td>37300.48</td>\n",
       "      <td>186.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>3664</td>\n",
       "      <td>WILLIAM GRANT &amp; SONS INC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>13643</td>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>2017-02-04</td>\n",
       "      <td>9848</td>\n",
       "      <td>202815.78</td>\n",
       "      <td>932.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>9815</td>\n",
       "      <td>WINE GROUP INC</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>13602</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>24747</td>\n",
       "      <td>149007.56</td>\n",
       "      <td>819.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>90058</td>\n",
       "      <td>ZORVINO VINEYARDS</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>13574</td>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>437</td>\n",
       "      <td>3608.11</td>\n",
       "      <td>16.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5169 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VendorNumber                   VendorName InvoiceDate  PONumber  \\\n",
       "0              105  ALTAMAR BRANDS LLC           2016-01-04      8124   \n",
       "1             4466  AMERICAN VINTAGE BEVERAGE    2016-01-07      8137   \n",
       "2              388  ATLANTIC IMPORTING COMPANY   2016-01-09      8169   \n",
       "3              480  BACARDI USA INC              2016-01-12      8106   \n",
       "4              516  BANFI PRODUCTS CORP          2016-01-07      8170   \n",
       "...            ...                          ...         ...       ...   \n",
       "5538          9622  WEIN BAUER INC               2017-01-06     13626   \n",
       "5539          9625  WESTERN SPIRITS BEVERAGE CO  2017-01-10     13661   \n",
       "5540          3664  WILLIAM GRANT & SONS INC     2017-01-02     13643   \n",
       "5541          9815  WINE GROUP INC               2017-01-03     13602   \n",
       "5542         90058  ZORVINO VINEYARDS            2017-01-05     13574   \n",
       "\n",
       "          PODate     PayDate  Quantity    Dollars  Freight Approval  \n",
       "0     2015-12-21  2016-02-16         6     214.26     3.47      NaN  \n",
       "1     2015-12-22  2016-02-21        15     140.55     8.57      NaN  \n",
       "2     2015-12-24  2016-02-16         5     106.60     4.61      NaN  \n",
       "3     2015-12-20  2016-02-05     10100  137483.78  2935.20      NaN  \n",
       "4     2015-12-24  2016-02-12      1935   15527.25   429.20      NaN  \n",
       "...          ...         ...       ...        ...      ...      ...  \n",
       "5538  2016-12-21  2017-02-10        90    1563.00     8.60      NaN  \n",
       "5539  2016-12-23  2017-02-18      4617   37300.48   186.50      NaN  \n",
       "5540  2016-12-22  2017-02-04      9848  202815.78   932.95      NaN  \n",
       "5541  2016-12-20  2017-02-08     24747  149007.56   819.54      NaN  \n",
       "5542  2016-12-18  2017-02-12       437    3608.11    16.60      NaN  \n",
       "\n",
       "[5169 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar todas las filas con valores faltantes: \n",
    "df4[df4.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5169)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar cuantas filas tienen datos faltante:\n",
    "df4.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Ver valores duplicados df4 es tu DataFrame\n",
    "duplicados = df4.duplicated().sum()\n",
    "\n",
    "print(f\"Total de filas duplicadas: {duplicados}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos en la columna 'Approval':\n",
      "[nan 'Frank Delahunt']\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que tu DataFrame es df4\n",
    "unique_values = df4['Approval'].unique()\n",
    "\n",
    "print(\"Valores √∫nicos en la columna 'Approval':\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llenar Nan con el valor de Frank Delahunt en la columna Approval para ir limpiando y homogenizando los datos:\n",
    "\n",
    "# df4['Approval'] = df4['Approval'].fillna(\"Frank Delahunt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calcular la media, moda y mediana de Approval para el dataframe df4:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Calcular la media, moda y mediana de la columna 'Approval'\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m mean_approval \u001b[38;5;241m=\u001b[39m \u001b[43mdf4\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mApproval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m mode_approval \u001b[38;5;241m=\u001b[39m df4[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApproval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# mode() devuelve una serie, tomamos el primer valor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m median_approval \u001b[38;5;241m=\u001b[39m df4[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApproval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian()\n",
      "File \u001b[1;32mc:\\Users\\Cami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6548\u001b[0m ):\n\u001b[1;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Cami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m  12422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Cami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Cami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6452\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6456\u001b[0m     )\n\u001b[1;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Cami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Cami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\Users\\Cami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\nanops.py:719\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    716\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Cami\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\_methods.py:52\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     51\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# Calcular la media, moda y mediana de Approval para el dataframe df4:\n",
    "\n",
    "# Calcular la media, moda y mediana de la columna 'Approval'\n",
    "\n",
    "#mean_approval = df4['Approval'].mean()\n",
    "#mode_approval = df4['Approval'].mode()[0]  # mode() devuelve una serie, tomamos el primer valor\n",
    "#median_approval = df4['Approval'].median()\n",
    "\n",
    "# Mostrar los resultados\n",
    "#print(f\"Media de Approval: {mean_approval}\")\n",
    "#print(f\"Moda de Approval: {mode_approval}\")\n",
    "#print(f\"Mediana de Approval: {median_approval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df4['Approval'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           InventoryId  Store  Brand                   Description   Size  \\\n",
      "0    69_MOUNTMEND_8412     69   8412     Tequila Ocho Plata Fresno  750mL   \n",
      "1     30_CULCHETH_5255     30   5255  TGI Fridays Ultimte Mudslide  1.75L   \n",
      "2    34_PITMERDEN_5215     34   5215  TGI Fridays Long Island Iced  1.75L   \n",
      "3  1_HARDERSFIELD_5255      1   5255  TGI Fridays Ultimte Mudslide  1.75L   \n",
      "4    76_DONCASTER_2034     76   2034     Glendalough Double Barrel  750mL   \n",
      "\n",
      "   VendorNumber                   VendorName  PONumber      PODate  \\\n",
      "0           105  ALTAMAR BRANDS LLC               8124  2015-12-21   \n",
      "1          4466  AMERICAN VINTAGE BEVERAGE        8137  2015-12-22   \n",
      "2          4466  AMERICAN VINTAGE BEVERAGE        8137  2015-12-22   \n",
      "3          4466  AMERICAN VINTAGE BEVERAGE        8137  2015-12-22   \n",
      "4           388  ATLANTIC IMPORTING COMPANY       8169  2015-12-24   \n",
      "\n",
      "  ReceivingDate InvoiceDate     PayDate  PurchasePrice  Quantity  Dollars  \\\n",
      "0    2016-01-02  2016-01-04  2016-02-16          35.71         6   214.26   \n",
      "1    2016-01-01  2016-01-07  2016-02-21           9.35         4    37.40   \n",
      "2    2016-01-02  2016-01-07  2016-02-21           9.41         5    47.05   \n",
      "3    2016-01-01  2016-01-07  2016-02-21           9.35         6    56.10   \n",
      "4    2016-01-02  2016-01-09  2016-02-16          21.32         5   106.60   \n",
      "\n",
      "   Classification  \n",
      "0               1  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ruta del archivo CSV (ajusta seg√∫n la ubicaci√≥n de tu archivo)\n",
    "ruta_csv5 = r\"C:\\\\Proyecto Final Henry\\\\DataBase\\\\PurchasesFINAL12312016.csv\"\n",
    "\n",
    "# Cargar el CSV en un DataFrame de Pandas\n",
    "df5 = pd.read_csv(ruta_csv5)\n",
    "\n",
    "# Mostrar las primeras filas del CSV\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2372474, 16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar el total de filas y columnas\n",
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InventoryId       0\n",
       "Store             0\n",
       "Brand             0\n",
       "Description       0\n",
       "Size              3\n",
       "VendorNumber      0\n",
       "VendorName        0\n",
       "PONumber          0\n",
       "PODate            0\n",
       "ReceivingDate     0\n",
       "InvoiceDate       0\n",
       "PayDate           0\n",
       "PurchasePrice     0\n",
       "Quantity          0\n",
       "Dollars           0\n",
       "Classification    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se revisa la cantidad de datos faltantes en la base de datos para continuar\n",
    "df5.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InventoryId</th>\n",
       "      <th>Store</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Size</th>\n",
       "      <th>VendorNumber</th>\n",
       "      <th>VendorName</th>\n",
       "      <th>PONumber</th>\n",
       "      <th>PODate</th>\n",
       "      <th>ReceivingDate</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>PayDate</th>\n",
       "      <th>PurchasePrice</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Dollars</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109668</th>\n",
       "      <td>34_PITMERDEN_3121</td>\n",
       "      <td>34</td>\n",
       "      <td>3121</td>\n",
       "      <td>Pinnacle Rainbow Sherbet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12546</td>\n",
       "      <td>JIM BEAM BRANDS COMPANY</td>\n",
       "      <td>10938</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>2016-07-13</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7</td>\n",
       "      <td>48.51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112426</th>\n",
       "      <td>34_PITMERDEN_5678</td>\n",
       "      <td>34</td>\n",
       "      <td>5678</td>\n",
       "      <td>Skinnygirl Pina Colada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12546</td>\n",
       "      <td>JIM BEAM BRANDS COMPANY</td>\n",
       "      <td>10938</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>2016-07-09</td>\n",
       "      <td>2016-07-13</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>6.93</td>\n",
       "      <td>6</td>\n",
       "      <td>41.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116302</th>\n",
       "      <td>39_EASTHALLOW_15365</td>\n",
       "      <td>39</td>\n",
       "      <td>15365</td>\n",
       "      <td>Alabaster 07 Tinta de Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9552</td>\n",
       "      <td>M S WALKER INC</td>\n",
       "      <td>10972</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>2016-07-07</td>\n",
       "      <td>2016-07-13</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>91.83</td>\n",
       "      <td>1</td>\n",
       "      <td>91.83</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 InventoryId  Store  Brand                 Description Size  \\\n",
       "1109668    34_PITMERDEN_3121     34   3121    Pinnacle Rainbow Sherbet  NaN   \n",
       "1112426    34_PITMERDEN_5678     34   5678      Skinnygirl Pina Colada  NaN   \n",
       "1116302  39_EASTHALLOW_15365     39  15365  Alabaster 07 Tinta de Toro  NaN   \n",
       "\n",
       "         VendorNumber                   VendorName  PONumber      PODate  \\\n",
       "1109668         12546  JIM BEAM BRANDS COMPANY         10938  2016-06-27   \n",
       "1112426         12546  JIM BEAM BRANDS COMPANY         10938  2016-06-27   \n",
       "1116302          9552  M S WALKER INC                  10972  2016-06-29   \n",
       "\n",
       "        ReceivingDate InvoiceDate     PayDate  PurchasePrice  Quantity  \\\n",
       "1109668    2016-07-04  2016-07-13  2016-08-16           6.93         7   \n",
       "1112426    2016-07-09  2016-07-13  2016-08-16           6.93         6   \n",
       "1116302    2016-07-07  2016-07-13  2016-08-21          91.83         1   \n",
       "\n",
       "         Dollars  Classification  \n",
       "1109668    48.51               1  \n",
       "1112426    41.58               1  \n",
       "1116302    91.83               2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar todas las filas con valores faltantes: \n",
    "df5[df5.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar cuantas filas tienen datos faltante:\n",
    "df5.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las filas de datos faltantes (si son pocos datos)\n",
    "df5 = df5.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2372471, 16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar el total de filas y columnas\n",
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Ver valores duplicados df5 es tu DataFrame\n",
    "duplicados = df5.duplicated().sum()\n",
    "\n",
    "print(f\"Total de filas duplicadas: {duplicados}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el dataset revisado, a el cual se le elimino una fila convalores NaN y se guarda a un nuevo archivo csv para poderlo utilizar posteriormente.\n",
    "df5.to_csv(\"PurchasesFINAL12312016Rev.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           InventoryId  Store  Brand                 Description        Size  \\\n",
      "0  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "1  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "2  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "3  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "4  1_HARDERSFIELD_1005      1   1005     Maker's Mark Combo Pack  375mL 2 Pk   \n",
      "\n",
      "   SalesQuantity  SalesDollars  SalesPrice SalesDate  Volume  Classification  \\\n",
      "0              1         16.49       16.49  1/1/2016     750               1   \n",
      "1              2         32.98       16.49  1/2/2016     750               1   \n",
      "2              1         16.49       16.49  1/3/2016     750               1   \n",
      "3              1         14.49       14.49  1/8/2016     750               1   \n",
      "4              2         69.98       34.99  1/9/2016     375               1   \n",
      "\n",
      "   ExciseTax  VendorNo                   VendorName  \n",
      "0       0.79     12546  JIM BEAM BRANDS COMPANY      \n",
      "1       1.57     12546  JIM BEAM BRANDS COMPANY      \n",
      "2       0.79     12546  JIM BEAM BRANDS COMPANY      \n",
      "3       0.79     12546  JIM BEAM BRANDS COMPANY      \n",
      "4       0.79     12546  JIM BEAM BRANDS COMPANY      \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ruta del archivo CSV (ajusta seg√∫n la ubicaci√≥n de tu archivo)\n",
    "ruta_csv6 = r\"C:\\\\Proyecto Final Henry\\\\DataBase\\\\SalesFINAL12312016.csv\"\n",
    "\n",
    "# Cargar el CSV en un DataFrame de Pandas\n",
    "df6 = pd.read_csv(ruta_csv6)\n",
    "\n",
    "# Mostrar las primeras filas del CSV\n",
    "print(df6.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 14)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar el total de filas y columnas\n",
    "df6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InventoryId       0\n",
       "Store             0\n",
       "Brand             0\n",
       "Description       0\n",
       "Size              0\n",
       "SalesQuantity     0\n",
       "SalesDollars      0\n",
       "SalesPrice        0\n",
       "SalesDate         0\n",
       "Volume            0\n",
       "Classification    0\n",
       "ExciseTax         0\n",
       "VendorNo          0\n",
       "VendorName        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se revisa la cantidad de datos faltantes en la base de datos para continuar\n",
    "df6.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InventoryId</th>\n",
       "      <th>Store</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Size</th>\n",
       "      <th>SalesQuantity</th>\n",
       "      <th>SalesDollars</th>\n",
       "      <th>SalesPrice</th>\n",
       "      <th>SalesDate</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Classification</th>\n",
       "      <th>ExciseTax</th>\n",
       "      <th>VendorNo</th>\n",
       "      <th>VendorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [InventoryId, Store, Brand, Description, Size, SalesQuantity, SalesDollars, SalesPrice, SalesDate, Volume, Classification, ExciseTax, VendorNo, VendorName]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar todas las filas con valores faltantes: \n",
    "df6[df6.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Ver valores duplicados df6 es tu DataFrame\n",
    "duplicados = df6.duplicated().sum()\n",
    "\n",
    "print(f\"Total de filas duplicadas: {duplicados}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
